{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhXAxvxQQKj3"
      },
      "source": [
        "<img src='https://github.com/Deci-AI/data-gradients/blob/master/src/data_gradients/assets/images/logo.png?raw=true'>\n",
        "\n",
        "\n",
        "## üëãüèΩ What's up! It's [Harpreet](https://twitter.com/DataScienceHarp)\n",
        "\n",
        "Welcome to this tutorial notebook on [DataGradients](https://github.com/Deci-AI/data-gradients) for **segmentation datasets**. DG is an open-source Python library for computer vision dataset analysis. If you're looking for the **object detection datasets notebook** you can find that [here.](bit.ly/dg-starter-notebook-od)\n",
        "\n",
        "I'll be guiding you through this notebook. At any point, if you get stuck or have questions, feel free to [read the docs](https://bit.ly/dg-docs) or get in touch:\n",
        "\n",
        "1) Send me an email with your issue: harpreet.sahota@deci.ai\n",
        "\n",
        "2) Hop into the [Deep Learning Daily (powered by Deci) Discord server](https://discord.gg/p9ecgRhDR8), and let me know what your question is.\n",
        "\n",
        "3) [Open an issue on GitHub](https://github.com/Deci-AI/data-gradients/issues/new)\n",
        "\n",
        "\n",
        "Let's get to it...\n",
        "\n",
        "\n",
        "# Introduction\n",
        "\n",
        "Whether you're working on image classification, [object detection](https://bit.ly/dg-starter-notebook-od), or semantic segmentation, DataGradients helps you gain insights and analyze your datasets effectively.\n",
        "\n",
        "In this tutorial, you'll explore the features and functionalities of DataGradients, guiding you through comprehensive data analysis for computer vision projects.\n",
        "\n",
        "With DataGradients, you can:\n",
        "\n",
        "- Analyze image features such as color distribution, brightness, and size.\n",
        "- Profile object detection datasets with metrics like bounding box area, intersection, and class frequency.\n",
        "- Understand segmentation datasets using object area, width, height, and class frequency.\n",
        "- Visualize samples for a better understanding.\n",
        "- And [much more](https://github.com/Deci-AI/data-gradients/blob/master/documentation/feature_description.md)\n",
        "\n",
        "Profiling your datasets has never been easier!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH6JJwsPSNB4"
      },
      "source": [
        "## üë®üèΩ‚Äçüîß Step 0: Installation\n",
        "\n",
        "Note: after installation is complete you will need to restart this notebook. Do the following: `Runtime -> Restart runtime`.\n",
        "\n",
        "Be careful NOT to select `Disconnect and delete runtime`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MdOWVad76Se"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# data-gradients\n",
        "!pip install -U -q git+https://github.com/Deci-AI/data-gradients.git\n",
        "\n",
        "# !pip install data-gradients\n",
        "\n",
        "# to get data from roboflow\n",
        "!pip install roboflow\n",
        "\n",
        "# for displaying pdfs as images in notebook\n",
        "!pip install pdf2image\n",
        "!apt-get install poppler-utils\n",
        "\n",
        "# for pretty printing json\n",
        "!pip install Pygments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkqllnKe5VFL"
      },
      "source": [
        "# üõ†Ô∏è Utility functions\n",
        "\n",
        "The `display_pdf_pages` function is a utility that displays each page of a PDF file as images in separate output cells.\n",
        "\n",
        "Given the path to a PDF file, it converts the PDF into a list of PIL Images using `pdf2image`.\n",
        "\n",
        "It then iterates through the list and displays each image using `IPython.display`.\n",
        "\n",
        "This function is useful for visually examining PDF content, such as reviewing pages or checking layouts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9q9jmV0H5NA3"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from pdf2image import convert_from_path\n",
        "from IPython.display import display\n",
        "\n",
        "def display_pdf_pages(pdf_path):\n",
        "    \"\"\"\n",
        "    Display each page of a PDF file as images in separate output cells.\n",
        "\n",
        "    Args:\n",
        "        pdf_path (str): The path to the PDF file.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: If the specified PDF file is not found.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Convert PDF to a list of PIL Images\n",
        "        images = convert_from_path(pdf_path)\n",
        "\n",
        "        # Display each image\n",
        "        for i, image in enumerate(images):\n",
        "            # Display the image\n",
        "            display(image)\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(\"The specified PDF file was not found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-vqYR4kLoGG"
      },
      "source": [
        "The `print_pretty_json` function opens a JSON file, formats the data with an indent of 4 spaces using `json.dumps`, applies syntax highlighting with `Pygments`, and prints the pretty-printed JSON data in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoEhr6LoLgqh"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pygments import highlight, lexers, formatters\n",
        "from pathlib import Path\n",
        "\n",
        "def print_pretty_json(file_path):\n",
        "    \"\"\"\n",
        "    Function to pretty print a JSON file with colorization.\n",
        "\n",
        "    Args:\n",
        "        file_path (Union[str, Path]): The path of the JSON file to be pretty-printed.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: If the file at `file_path` doesn't exist.\n",
        "        json.JSONDecodeError: If the file at `file_path` is not valid JSON.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Open the file\n",
        "        with open(file_path, 'r') as f:\n",
        "            # Load the JSON data from the file\n",
        "            data = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
        "    except json.JSONDecodeError:\n",
        "        raise json.JSONDecodeError(\"Invalid JSON file\", \"\", 0)\n",
        "\n",
        "    # Pretty print the JSON data with an indent of 4 spaces\n",
        "    formatted_json = json.dumps(data, indent=4)\n",
        "\n",
        "    # Colorize the pretty-printed JSON data\n",
        "    colorful_json = highlight(formatted_json,\n",
        "                              lexers.JsonLexer(),\n",
        "                              formatters.TerminalFormatter()\n",
        "                              )\n",
        "\n",
        "    # Print the colorized, pretty-printed JSON data\n",
        "    print(colorful_json)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIc3dl6XSWTI"
      },
      "source": [
        "## ‚§µÔ∏è Step 1: Download Dataset\n",
        "\n",
        "To demonstrate the analysis capabilities of DataGradients, we will work with a portion of the [BDD dataset](https://bdd-data.berkeley.edu/), a popular computer vision dataset for autonomous driving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcBFKcjV8FNb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "BDD_DATASET_DOWNLOAD_PATH=\"/content\"\n",
        "\n",
        "bdd_dataset_dir_path = BDD_DATASET_DOWNLOAD_PATH + os.path.sep + 'bdd_example'\n",
        "\n",
        "if os.path.isdir(bdd_dataset_dir_path):\n",
        "    print('bdd dataset already downloaded...')\n",
        "else:\n",
        "    print('Downloading and extracting bdd dataset to: ' + BDD_DATASET_DOWNLOAD_PATH)\n",
        "    ! mkdir $BDD_DATASET_DOWNLOAD_PATH\n",
        "    %cd $BDD_DATASET_DOWNLOAD_PATH\n",
        "    ! wget https://deci-pretrained-models.s3.amazonaws.com/bdd_example.zip\n",
        "    ! unzip --qq bdd_example.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7dvrawUUrD7"
      },
      "source": [
        "## üíæ Step 2: Instantiating Dataloaders\n",
        "\n",
        "To use DataGradients, you need to be equipped with a few prerequisites:\n",
        "\n",
        "- **Dataset**: Includes a Train set and a Validation or a Test set.\n",
        "\n",
        "- **Class Names**: A list of the unique categories present in your dataset.\n",
        "\n",
        "- **Iterable**: A method to iterate over your Dataset providing images and labels. This can be any of the following:\n",
        "  - PyTorch Dataloader\n",
        "  - PyTorch Dataset\n",
        "  - Generator that yields image/label pairs\n",
        "  - Any other iterable you use for model training/validation\n",
        "\n",
        "DataGradients provides some functionality that allows you to easily load your data without any extra coding needed:\n",
        "- `CocoFormatSegmentationDataset`\n",
        "- `CocoSegmentationDataset`\n",
        "- `VOCFormatSegmentationDataset`\n",
        "- `VOCSegmentationDataset`\n",
        "\n",
        "You can learn more about those [here.](https://github.com/Deci-AI/data-gradients/blob/master/documentation/datasets.md)\n",
        "\n",
        "\n",
        "#### üö® If your dataset and annotations is in a custom format, you can use DataGradients Dataset Adapters. Learn more about those [here](https://github.com/Deci-AI/data-gradients#dataset-adapters).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJp0H03mOBgM"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import Compose, ToTensor\n",
        "\n",
        "from data_gradients.datasets.bdd_dataset import BDDDataset\n",
        "\n",
        "    # Create torch DataSet\n",
        "train_dataset = BDDDataset(\n",
        "        data_folder=\"/content/bdd_example\",\n",
        "        split=\"train\",\n",
        "        transform=Compose([ToTensor()]),\n",
        "        target_transform=Compose([ToTensor()]),\n",
        "    )\n",
        "val_dataset = BDDDataset(\n",
        "        data_folder=\"/content/bdd_example\",\n",
        "        split=\"val\",\n",
        "        transform=Compose([ToTensor()]),\n",
        "        target_transform=Compose([ToTensor()]),\n",
        "    )\n",
        "\n",
        "    # Create torch DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=8)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAGrrq_LN0C0"
      },
      "source": [
        "## üìä Step 3: Perform Analysis\n",
        "\n",
        "Now that you have your dataset loaded and ready, its time to profile it using DataGradients.\n",
        "\n",
        "In this section, you'll use the `SegmentationAnalysisManager` class from DataGradients to analyze your dataset. This will trigger feature extraction, visualization, and an interpretation processes provided by DataGradients.\n",
        "\n",
        "**The time it takes to analyze your dataset depends on its size. If your dataset is large, it may take 20 minutes or more.**\n",
        "\n",
        "You instantiate the `SegmentationAnalysisManager` with the following arguments:\n",
        "\n",
        "- `report_title`: A title for the analysis report.\n",
        "\n",
        "- `train_data` and `val_data`: The dataloaders for the training and validation sets, respectively.\n",
        "\n",
        "- `class_names`: The list of class names present in the dataset.\n",
        "\n",
        "**üîò There are optional parameters that you can adjust as needed**:\n",
        "\n",
        "- `class_names_to_use`: The subset of class names we want to analyze if you're interested in only certain classes.\n",
        "\n",
        "- `images_extractor` and `labels_extractor`: Custom functions to extract images and labels from the dataset if needed.\n",
        "\n",
        "- `threshold_soft_labels`: A threshold value for soft labels, converting them to hard labels.\n",
        "\n",
        "- `batches_early_stop`: The number of batches to analyze before early stopping.\n",
        "\n",
        "You can find more information about these parameters in the [`SegmentationAnalysisManager` class documentation](https://github.com/Deci-AI/data-gradients/blob/master/src/data_gradients/managers/segmentation_manager.py).\n",
        "\n",
        "Once we have instantiated the `SegmentationAnalysisManager`, you can run the analysis by calling the `run()` method.\n",
        "\n",
        "### You'll be prompted for information about your annotations:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBVvgtfQYHQb"
      },
      "outputs": [],
      "source": [
        "from data_gradients.managers.segmentation_manager import SegmentationAnalysisManager\n",
        "import matplotlib\n",
        "\n",
        "matplotlib.use('Agg') # This line is only for Colab\n",
        "\n",
        "analyzer = SegmentationAnalysisManager(\n",
        "        report_title=\"BDD Subset Example\",\n",
        "        train_data=train_loader,\n",
        "        val_data=val_loader,\n",
        "        class_names=BDDDataset.CLASS_NAMES,\n",
        "        class_names_to_use=BDDDataset.CLASS_NAMES[:-1],\n",
        "        # Optionals\n",
        "        images_extractor=None,\n",
        "        labels_extractor=None,\n",
        "        threshold_soft_labels=0.5,\n",
        "        batches_early_stop=75,\n",
        "    )\n",
        "\n",
        "analyzer.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4N6LSinpaPnG"
      },
      "source": [
        "## Step 4: View Full PDF Report\n",
        "\n",
        "When you created the `analyzer`, you passed a value for `report_title`.\n",
        "\n",
        "The report will be saved to a folder in your current working directory that corresponds to that value.\n",
        "\n",
        "If you want to save it in a different folder, you can pass the path to `log_dir` in the `SegmentationAnalysisManager` constructor.\n",
        "\n",
        "Inside the log directory, you will find a complete PDF report that summarizes and provides insights on feature extractors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JhPzfwooApGx"
      },
      "outputs": [],
      "source": [
        "# this function was defined and described at the beginning of this notebook\n",
        "display_pdf_pages(\"/content/logs/BDD_Subset_Example/Report.pdf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7ef72LUA133"
      },
      "source": [
        "### ‚¨áÔ∏è Download Report\n",
        "\n",
        "Since this is a Google Colab notebook, the report isn't saved to your local drive. If you want to download the report you can do so by running the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjKag797hKv2"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/logs/BDD_Subset_Example/Report.pdf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvx7R-e_Eo3R"
      },
      "source": [
        "### üìÉ Accessing JSON report.\n",
        "\n",
        "You can also access the json report. This could be helpful to have if you want to save it and analyze changes in your data characteristics over time.\n",
        "\n",
        "Note: I left the below cell commented out because it will make the notebook long and messy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqM6CTqZCLXi"
      },
      "outputs": [],
      "source": [
        "# report_json = \"/content/logs/BDD_Subset_Example/summary.json\"\n",
        "# print_pretty_json(report_json)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jQiJQfd0avE"
      },
      "source": [
        "# üìÑ Individual analysis.\n",
        "\n",
        "If you only need one or a few analyses instead of the entire report, you can easily do so with the `run_segmentation_analysis` function.\n",
        "\n",
        " is a convenient utility that allows you to perform an individual analysis (as opposed to complete report) with ease.\n",
        "\n",
        "It takes various parameters to configure the analysis settings:\n",
        "\n",
        "- `report_title`: The title of the analysis report.\n",
        "- `feature_extractors`: A list of feature extractors to use for analysis.\n",
        "\n",
        "\n",
        "### You can choose from the following options for segmentation datasets:\n",
        "\n",
        "#### üîç [ImageColorDistribution](https://github.com/Deci-AI/data-gradients/blob/master/src/data_gradients/feature_extractors/common/image_color_distribution.py)\n",
        "\n",
        "This is a comparison between the RGB and grayscale intensity distributions (0-255) of the entire dataset, assuming the RGB channel ordering.\n",
        "\n",
        "It helps to detect differences in image characteristics between the two datasets and potential flaws in the augmentation process.\n",
        "\n",
        "For example, a significant difference in the mean value of a specific color between the two datasets could indicate an issue with augmentation.\n",
        "\n",
        "#### üåì [ImagesAverageBrightness](https://github.com/Deci-AI/data-gradients/blob/master/src/data_gradients/feature_extractors/common/image_average_brightness.py)\n",
        "\n",
        "This graph displays how the brightness of each dataset's images is distributed.\n",
        "\n",
        "This can reveal discrepancies between the training and validation sets.\n",
        "\n",
        "For example, it may show that the training set only has daytime images while the validation set only has nighttime images.\n",
        "\n",
        "#### üìè [ImagesResolution](https://github.com/Deci-AI/data-gradients/blob/master/src/data_gradients/feature_extractors/common/image_resolution.py)\n",
        "\n",
        "The histograms show how the image height and width are distributed.\n",
        "\n",
        "If any images were resized or added with padding, the histograms will display the size after these modifications.\n",
        "\n",
        "\n",
        "#### üìê [SegmentationBoundingBoxArea](https://github.com/Deci-AI/data-gradients/blob/master/src/data_gradients/feature_extractors/segmentation/bounding_boxes_area.py)\n",
        "\n",
        "This graph shows the distribution of object area for each class.\n",
        "\n",
        "This can highlight distribution gap in object size between the training and validation splits, which can harm the model performance.\n",
        "\n",
        "Another thing to keep in mind is that having too many very small objects may indicate that your are down sizing your original image to a low resolution that is not appropriate for your objects.\n",
        "\n",
        "#### üìè [SegmentationBoundingBoxResolution](https://github.com/Deci-AI/data-gradients/blob/master/src/data_gradients/feature_extractors/segmentation/bounding_boxes_resolution.py)\n",
        "\n",
        "Object size differences can impact accuracy.\n",
        "\n",
        "Heat maps show how objects are distributed by width and height for each class.\n",
        "\n",
        "#### üìä [SegmentationClassFrequency](https://github.com/Deci-AI/data-gradients/blob/master/src/data_gradients/feature_extractors/segmentation/classes_frequency.py)\n",
        "\n",
        "This bar graph shows how often each class appears, which can help identify differences in distribution between the training and validation data.\n",
        "\n",
        "If a class only appears in the validation set, it is likely that the model will not be able to accurately predict that class.\n",
        "\n",
        "\n",
        "#### üìç [SegmentationClassHeatmap](https://github.com/Deci-AI/data-gradients/blob/master/src/data_gradients/feature_extractors/segmentation/classes_heatmap_per_class.py)\n",
        "\n",
        "\n",
        "The heatmap shows where there are a lot of objects in the images, giving you an idea of how they are spread out.\n",
        "\n",
        "By looking at the heatmap, you can see if the objects are mostly grouped together in certain areas or if they are spread out evenly.\n",
        "\n",
        "This can help you figure out if the objects are in the right places that you're interested in.\n",
        "\n",
        "#### üìä [SegmentationClassesPerImageCount](https://github.com/Deci-AI/data-gradients/blob/master/src/data_gradients/feature_extractors/segmentation/classes_frequency_per_image.py)\n",
        "\n",
        "The graph illustrates the frequency of each class appearing in an image.\n",
        "\n",
        "It indicates whether the occurrence of each class is consistent across all images or varies from one image to another.\n",
        "\n",
        "#### üßÆ [SegmentationComponentsConvexity](https://github.com/Deci-AI/data-gradients/blob/master/src/data_gradients/feature_extractors/segmentation/components_convexity.py)\n",
        "\n",
        "This graph displays the distribution of convexity values of objects in both the training and validation sets.\n",
        "\n",
        "Higher convexity values indicate complex structures that could make accurate segmentation more difficult.\n",
        "\n",
        "\n",
        "####  üîç [SegmentationComponentsErosion](https://github.com/Deci-AI/data-gradients/blob/master/src/data_gradients/feature_extractors/segmentation/components_erosion.py)\n",
        "\n",
        "This evaluating the stability of objects through morphological opening, which involves erosion followed by dilation.\n",
        "\n",
        "If there are many small components, the number of components may decrease, potentially causing noise in our annotations (such as \"sprinkles\").\n",
        "\n",
        "\n",
        "#### üìä [SegmentationComponentsPerImageCount](https://github.com/Deci-AI/data-gradients/blob/master/src/data_gradients/feature_extractors/segmentation/component_frequency_per_image.py)\n",
        "\n",
        "The graphs display the number of various objects present in images.\n",
        "\n",
        "This information is useful especially when there are numerous objects in the image, as some models have a feature that filters the top k results.\n",
        "\n",
        "\n",
        "#### üëÅÔ∏è [SegmentationSampleVisualization](SegmentationSampleVisualization)\n",
        "\n",
        "The sample visualization feature presents images and labels in a visual format, which helps you better comprehend the makeup of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEH8o6l5KfSX"
      },
      "outputs": [],
      "source": [
        "def run_segmentation_analysis(report_title,\n",
        "                           feature_extractors,\n",
        "                           train_data,\n",
        "                           val_data,\n",
        "                           class_names,\n",
        "                           class_names_to_use):\n",
        "    \"\"\"\n",
        "    Run the detection analysis using the provided parameters.\n",
        "\n",
        "    Args:\n",
        "        report_title (str): Title of the analysis report.\n",
        "        feature_extractors (str): Feature extractors to be used.\n",
        "        train_data (str): Training data for the analysis.\n",
        "        val_data (str): Validation data for the analysis.\n",
        "        class_names (list): List of class names for the analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create an instance of SegmentationAnalysisManager\n",
        "    analyzer = SegmentationAnalysisManager(\n",
        "        report_title=report_title,\n",
        "        feature_extractors=feature_extractors,\n",
        "        train_data=train_data,\n",
        "        val_data=val_data,\n",
        "        class_names=class_names,\n",
        "        class_names_to_use=class_names_to_use\n",
        "    )\n",
        "\n",
        "    # Run the analysis\n",
        "    analyzer.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMCXpEcHSiVd"
      },
      "outputs": [],
      "source": [
        "run_segmentation_analysis(report_title= 'SegmentationComponentsConvexity',\n",
        "                           feature_extractors='SegmentationComponentsConvexity',\n",
        "                           train_data=train_dataset,\n",
        "                           val_data=val_dataset,\n",
        "                          class_names=BDDDataset.CLASS_NAMES,\n",
        "                          class_names_to_use=BDDDataset.CLASS_NAMES[:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nm5AR_nhS-Ci"
      },
      "outputs": [],
      "source": [
        "display_pdf_pages(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84dZkCbTT9mr"
      },
      "outputs": [],
      "source": [
        "report_json = \"\"\n",
        "print_pretty_json(report_json)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e17NJ2v4-09"
      },
      "source": [
        "# üîö You've made it to the end!\n",
        "\n",
        "If you think DataGradients is useful, head over to GitHub and [‚≠êÔ∏è the repo](https://github.com/Deci-AI/data-gradients).\n",
        "\n",
        "\n",
        "### Some datasets you might want to try on your own:\n",
        "\n",
        "\n",
        "# Give SuperGradients a try!\n",
        "Now that you've analyzed your segmentation, go and train a YOLO-NAS model on it.\n",
        "\n",
        "[Here's a starter notebook the get you on your way!](https://bit.ly/yolo-nas-starter-notebook)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}